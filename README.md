
---

## ğŸ« Pneumonia Detection from Chest X-Ray Images using Transfer Learning

This project explores how deep learning models can assist in detecting **pneumonia from chest X-ray scans**.
It was developed as a **learning & research-grade experiment** to understand medical imaging with CNNs, not as a final clinical tool.

Our focus:

* âœ… Understanding transfer learning on medical images
* âœ… Comparing multiple CNN architectures
* âœ… Observing class imbalance effects
* âœ… Using **Grad-CAM** for explainability
* âœ… Practicing ethical ML â€” no exaggerated claims

---

## ğŸ“¦ Dataset

**Chest X-Ray (Pneumonia) dataset**
Classes: `NORMAL` vs `PNEUMONIA`

Folder-split dataset ~ train / test / val

> This dataset is commonly used in research papers for pneumonia classification experiments.

---

## ğŸ§  Models Used & Why

We experimented with 4 well-known CNN architectures:

| Model           | Reason for Choice                                |
| --------------- | ------------------------------------------------ |
| **DenseNet121** | Strong performance in medical imaging literature |
| ResNet50        | Classic baseline for deep feature extraction     |
| EfficientNetB0  | Parameter-efficient modern architecture          |
| MobileNetV2     | Lightweight model for low-resource inference     |

Each started from **ImageNet weights** â†’ fine-tuned on chest X-rays.

---

## ğŸ“Š Key Observations

* **DenseNet121 performed best** after fine-tuning
* Increasing epochs improved generalization
* Class imbalance affected early results
* Threshold tuning (~0.69) improved decision boundary
* Augmentation helped reduce overfitting

> Final results are promising but **not production / clinical ready**
> This is part of a learning journey.

---

## ğŸ“ˆ Evaluation & What We Learned

We calculated:

* âœ… Accuracy
* âœ… Precision, Recall, F1
* âœ… Confusion Matrix
* âœ… ROC-AUC
* âœ… Grad-CAM visualizations

**Why this matters:**
Medical models must be interpretable â€” not just accurate.
Grad-CAM helped verify model focus on lung regions (and spot mistakes).

---

## ğŸ” Explainability (Grad-CAM)

Heatmaps were generated to visualize what the model looks at.

| Example Output                            |
| ----------------------------------------- |
| *(grad-cam images go here once uploaded)* |

Some images showed correct lung attention âœ…
Some highlighted irrelevant areas âŒ

> This reflection was an important learning outcome.

---

## ğŸ“ Project Structure

```
ğŸ“‚ project
â”‚â”€â”€ notebook.ipynb  ~ full training & testing
â”‚â”€â”€ models/         ~ saved .h5 models
â”‚â”€â”€ results/        ~ CM, ROC, Grad-CAM
â”‚â”€â”€ README.md       ~ (this file)
```

---

## âš™ï¸ Workflow in Colab

1ï¸âƒ£ Load and inspect dataset
2ï¸âƒ£ Create generators + augmentation
3ï¸âƒ£ Train multiple CNNs
4ï¸âƒ£ Compare metrics
5ï¸âƒ£ Tune threshold
6ï¸âƒ£ Generate Grad-CAM maps
7ï¸âƒ£ Save best model

Each stage helped understand ML lifecycle in medical imaging.

---

## ğŸª« Limitations & Ethical Note

* Small validation subset
* Short training due to Colab compute limits
* No external validation data
* Not medically approved

âš ï¸ **This project does not diagnose disease.**
It is only an academic exercise.

---

## ğŸ¯ What This Project Achieved

* Built practical intuition for medical deep learning
* Gained hands-on experience in transfer learning
* Understood model interpretability importance
* Learned responsible reporting of results

---

## ğŸ™‹â€â™€ï¸ Author Note

This project was created as part of my journey in **AI & Data Science**, focusing on healthcare applications and ethical ML.

Feel free to explore, learn, and suggest improvements!

If you found this useful, â­ the repo ğŸŒŸ

---

